{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project3 Web APIs & Classification\n",
    "\n",
    "### Part 1 Data Cleaning and Exploratory Data Analysis\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Gather Data](#Gather-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "To classify Reddit posts from r/Premier league and r/NBA using Natural Language Processing (NLP) and Modeling. The model evaluated and selected based on Accuracy score is expected to predict to which subreddit a given post belongs to.\n",
    "\n",
    "The model should then help Reddit data science team to advise their advertisers on spending forecast for targeted marketing campaigns of products and services based on the predicted subreddit. Here Reddit data science team is the primary stake holder and advertising companies are the secondary stakeholders.\n",
    "\n",
    "**Background**<br>\n",
    "The objective is to find out the attributes of each group and their online behaviour:<br>With the information gathered, business can<br>\n",
    "        1) Decide how much advertising dollars to spend and on which group to obtain better ROI.<br>\n",
    "        2) Types of products and services to be advertised.<br>\n",
    "        3) Frequency of advertisement.<br>\n",
    "        4) Types of advertisement.<br>\n",
    "        5) KPI expected from Reddit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data\n",
    " 1) Extract posts from the 2 subreddits that records football league system. -Premier League and NBA.<br>\n",
    " 2) Attempt to extract 75 pages of posts equivalent to approx. 2000 unique posts per subreddit.<br>\n",
    " 3) Write them to individual .csv files for recording purposes.<br>\n",
    " 4) Read these .csv files to separate dataframes and examine data extracted.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libtaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The 2 Subreddit to scrap\n",
    "url1='https://www.reddit.com/r/PremierLeague/.json'\n",
    "url2='https://www.reddit.com/r/nba/.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.ceil(1000/25)) #Return ceil value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that scrap posts \n",
    "def reddit_scrapper(subreddit,n_posts):\n",
    "    url=f'https://www.reddit.com/r/{subreddit}/.json'\n",
    "    headers={'User-agent':'Elizabeth'}\n",
    "    posts=[]\n",
    "    after = None\n",
    "    n_scrapes = int(np.ceil(n_posts/25))\n",
    "    for i in range(n_scrapes):\n",
    "        if i%5==0:\n",
    "            print (i)\n",
    "            \n",
    "        if after==None:\n",
    "            params={}\n",
    "        else:\n",
    "            params={'after':after}\n",
    "            \n",
    "        res=requests.get(url,params=params,headers=headers)\n",
    "    \n",
    "        if res.status_code==200:\n",
    "            the_json=res.json()\n",
    "            posts.extend(the_json['data']['children'])\n",
    "            after=the_json['data']['after']\n",
    "        else:\n",
    "            print('Status error', res.status.code)\n",
    "            break\n",
    "        \n",
    "        # generate a random sleep duration to look more 'natural'\n",
    "        sleep_duration = random.randint(2,6)\n",
    "        time.sleep(sleep_duration)\n",
    "        \n",
    "    len(set([p['data']['name'] for p in posts]))\n",
    "    df_interim=pd.DataFrame(posts)\n",
    "    df = pd.DataFrame(df_interim['data'].apply(pd.Series))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "#Loading 2000 posts for subreddit Premier league\n",
    "df_pl = reddit_scrapper('PremierLeague', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving post of subreddit Premier League as CSV file\n",
    "df_pl.to_csv(r'..\\datasets\\pl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "#Loading 2000 posts for subreddit NBA\n",
    "df_nba = reddit_scrapper('nba', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving post of subreddit Premier League as CSV file\n",
    "df_nba.to_csv(r'..\\datasets\\nba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>url_overridden_by_dest</th>\n",
       "      <th>preview</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>poll_data</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PremierLeague</td>\n",
       "      <td>What's on your mind? This is the daily discuss...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>r/PremierLeague Daily Discussion</td>\n",
       "      <td>[{'a': ':xpl:', 'e': 'emoji', 'u': 'https://em...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PremierLeague</td>\n",
       "      <td>The front of a football jersey is a huge get f...</td>\n",
       "      <td>t2_1c0fq32l</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Football shirt sponsors are often relatively s...</td>\n",
       "      <td>[{'e': 'text', 't': 'Discussion'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approved_at_utc      subreddit  \\\n",
       "0              NaN  PremierLeague   \n",
       "1              NaN  PremierLeague   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0  What's on your mind? This is the daily discuss...        t2_6l4z3  False   \n",
       "1  The front of a football jersey is a huge get f...     t2_1c0fq32l  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "\n",
       "                                               title  \\\n",
       "0                   r/PremierLeague Daily Discussion   \n",
       "1  Football shirt sponsors are often relatively s...   \n",
       "\n",
       "                                 link_flair_richtext  ... post_hint  \\\n",
       "0  [{'a': ':xpl:', 'e': 'emoji', 'u': 'https://em...  ...       NaN   \n",
       "1                 [{'e': 'text', 't': 'Discussion'}]  ...       NaN   \n",
       "\n",
       "   url_overridden_by_dest  preview  is_gallery  media_metadata  gallery_data  \\\n",
       "0                     NaN      NaN         NaN             NaN           NaN   \n",
       "1                     NaN      NaN         NaN             NaN           NaN   \n",
       "\n",
       "   crosspost_parent_list  crosspost_parent poll_data  author_cakeday  \n",
       "0                    NaN               NaN       NaN             NaN  \n",
       "1                    NaN               NaN       NaN             NaN  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl=pd.read_csv(r'..\\datasets\\pl.csv')\n",
    "pl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>url_overridden_by_dest</th>\n",
       "      <th>preview</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td># Game Threads Index (January 13, 2021):\\n\\n|T...</td>\n",
       "      <td>t2_6vjwa</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Vintage Wednesday Thread + Game Thread Index</td>\n",
       "      <td>[{'e': 'text', 't': 'Index Thread'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nba</td>\n",
       "      <td>Here is a place to have in depth, x's and o's,...</td>\n",
       "      <td>t2_6vjwa</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[SERIOUS NEXT DAY THREAD] Post-Game Discussion...</td>\n",
       "      <td>[{'e': 'text', 't': 'Discussion'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approved_at_utc subreddit  \\\n",
       "0              NaN       nba   \n",
       "1              NaN       nba   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0  # Game Threads Index (January 13, 2021):\\n\\n|T...        t2_6vjwa  False   \n",
       "1  Here is a place to have in depth, x's and o's,...        t2_6vjwa  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "\n",
       "                                               title  \\\n",
       "0       Vintage Wednesday Thread + Game Thread Index   \n",
       "1  [SERIOUS NEXT DAY THREAD] Post-Game Discussion...   \n",
       "\n",
       "                    link_flair_richtext  ... num_crossposts  media  is_video  \\\n",
       "0  [{'e': 'text', 't': 'Index Thread'}]  ...              0    NaN     False   \n",
       "1    [{'e': 'text', 't': 'Discussion'}]  ...              0    NaN     False   \n",
       "\n",
       "  post_hint  url_overridden_by_dest  preview  crosspost_parent_list  \\\n",
       "0       NaN                     NaN      NaN                    NaN   \n",
       "1       NaN                     NaN      NaN                    NaN   \n",
       "\n",
       "   crosspost_parent media_metadata  author_cakeday  \n",
       "0               NaN            NaN             NaN  \n",
       "1               NaN            NaN             NaN  \n",
       "\n",
       "[2 rows x 112 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba=pd.read_csv(r'..\\datasets\\nba.csv')\n",
    "nba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1987, 115), (2001, 112))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.shape,nba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 627)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.selftext.isnull().sum(),nba.selftext.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.title.isnull().sum(),nba.title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PremierLeague    1987\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nba    2001\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved',\n",
       "       'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext',\n",
       "       ...\n",
       "       'post_hint', 'url_overridden_by_dest', 'preview', 'is_gallery',\n",
       "       'media_metadata', 'gallery_data', 'crosspost_parent_list',\n",
       "       'crosspost_parent', 'poll_data', 'author_cakeday'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
